{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMGu-UMvIsRf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import UnidentifiedImageError\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive (if using Google Colab)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "hNocDoagIspe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import UnidentifiedImageError\n",
        "import os"
      ],
      "metadata": {
        "id": "5WIhn5u3JpmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "YIskmolcMEWz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataset class to preprocess and filter out corrupted images\n",
        "class CustomImageFolder(ImageFolder):\n",
        "    def __getitem__(self, index):\n",
        "        try:\n",
        "            return super().__getitem__(index)\n",
        "        except UnidentifiedImageError:\n",
        "            print(f\"Caught UnidentifiedImageError, skipping image at index {index}.\")\n",
        "            return self.__getitem__(index + 1)\n"
      ],
      "metadata": {
        "id": "8FXwd1vbMETZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset and automatically split into train and test sets\n",
        "dataset_path = '/content/drive/MyDrive/dataf/flowers'\n",
        "dataset = CustomImageFolder(dataset_path, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "yWn0rjydMEPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataLoaders for train and test setse\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "7JxxPP-VMEMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained ResNet-50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze all layers except the last one\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc.requires_grad = True\n",
        "\n",
        "num_classes = len(train_dataset.dataset.classes)\n",
        "model.fc = nn.Linear(model.fc.in_features, num_classes)\n"
      ],
      "metadata": {
        "id": "beoRoxJjMEJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "vELVHrB_MEHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "id": "OI9sBLGtMEDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize TensorBoard writer\n",
        "writer = SummaryWriter()\n"
      ],
      "metadata": {
        "id": "sXq0H2XkMEAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "xOMn-fRSItCP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "EzI8PlSfRWt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "num_epochs = 3\n",
        "train_accuracy_values = []  # List to store training accuracy values\n",
        "train_loss_values = []      # List to store training loss values\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_train += labels.size(0)\n",
        "        correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = 100 * correct_train / total_train\n",
        "\n",
        "    train_accuracy_values.append(train_accuracy)  # Store accuracy value\n",
        "    train_loss_values.append(avg_loss)            # Store loss value\n",
        "\n",
        "    writer.add_scalar('Loss/train', avg_loss, epoch)\n",
        "    writer.add_scalar('Accuracy/train', train_accuracy, epoch)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {avg_loss:.4f} - Train Accuracy: {train_accuracy:.2f}%\")\n",
        "\n",
        "print('Training finished.')\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "6RtHmdzFQZqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy on the test set\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "test_losses = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        test_loss = criterion(outputs, labels)\n",
        "        test_losses.append(test_loss.item())\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "avg_test_loss = sum(test_losses) / len(test_losses)\n",
        "test_accuracy = 100 * correct_test / total_test\n",
        "\n",
        "writer = SummaryWriter()\n",
        "writer.add_scalar('Loss/test', avg_test_loss, num_epochs)\n",
        "writer.add_scalar('Accuracy/test', test_accuracy, num_epochs)\n",
        "print(f\"Test Loss: {avg_test_loss:.4f} - Test Accuracy: {test_accuracy:.2f}%\")\n",
        "writer.close()\n"
      ],
      "metadata": {
        "id": "daxiKJj4rhnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot training accuracy and loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(num_epochs), train_accuracy_values, label='Train Accuracy', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(num_epochs), train_loss_values, label='Train Loss', marker='o')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JsQ4aONdRykB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot training and test accuracy\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot([0], [train_accuracy_values[0]], 'bo', label='Train Accuracy')\n",
        "plt.plot([0], [test_accuracy], 'ro', label='Test Accuracy')\n",
        "plt.xticks([0], ['Epoch 1'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Test Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0JFFbuF3Rydv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test phase\n",
        "test_losses = []\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        test_losses.append(loss.item())\n",
        "\n",
        "avg_test_loss = sum(test_losses) / len(test_losses)\n",
        "\n",
        "# Plot training and test loss\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot([0], [train_loss_values[0]], 'bo', label='Train Loss')\n",
        "plt.plot([0], [avg_test_loss], 'ro', label='Test Loss')\n",
        "plt.xticks([0], ['Epoch 1'])\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Test Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lZ0R5GccQZnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and test a random image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Path to a random image in your dataset\n",
        "random_image_path = '/content/drive/MyDrive/dataf/flowers/daisy test image.jpg'\n",
        "\n",
        "# Load and preprocess the image\n",
        "random_image = Image.open(random_image_path)\n",
        "random_image = transform(random_image).unsqueeze(0).to(device)  # Preprocess and move to GPU\n",
        "\n",
        "# Get the predicted class\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "with torch.no_grad():\n",
        "    output = model(random_image)\n",
        "    _, predicted_class = torch.max(output, 1)\n",
        "\n",
        "# Map the predicted class index to the class label\n",
        "class_index = predicted_class.item()\n",
        "class_label = train_dataset.dataset.classes[class_index]\n",
        "\n",
        "# Display the result\n",
        "plt.imshow(np.array(random_image.squeeze().cpu().permute(1, 2, 0)))  # Display the image\n",
        "plt.title(f\"Predicted Class: {class_label}\")\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UOSe7IzWWcHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NRRoLVj-WcEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VgHRazPWWb8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Quxgje1gWoya"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}